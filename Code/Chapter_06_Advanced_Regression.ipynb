{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. Advanced Regression\n",
    "## Author: Rahul Bhadani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kernel Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15\n",
    "from scipy.stats import norm\n",
    "\n",
    "def tricube_kernel(x):\n",
    "    \"\"\"Tricube kernel function scaled to max 1.\"\"\"\n",
    "    abs_x = np.abs(x)\n",
    "    return np.where(abs_x < 1, ((70 / 81) * (1 - abs_x**3) ** 3) / (70 / 81), 0)\n",
    "\n",
    "def rectangular_kernel(x):\n",
    "    \"\"\"Rectangular (uniform) kernel function scaled to max 1.\"\"\"\n",
    "    return np.where(np.abs(x) < 1, 1, 0)\n",
    "\n",
    "def normal_kernel(x):\n",
    "    \"\"\"Normal (Gaussian) kernel function, rescaled to max 1.\"\"\"\n",
    "    return norm.pdf(x) / norm.pdf(0)\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(-4.5, 4.5, 400)\n",
    "\n",
    "# Compute kernel values\n",
    "y_tricube = tricube_kernel(x)\n",
    "y_normal = normal_kernel(x)\n",
    "y_rectangular = rectangular_kernel(x)\n",
    "\n",
    "# Plot the kernel functions\n",
    "plt.figure(figsize=(12, 6), dpi=600)\n",
    "plt.plot(x, y_tricube, 'r', linestyle='-', alpha=0.5, label='Tricube')\n",
    "plt.plot(x, y_normal, 'b--', label='Normal')\n",
    "plt.plot(x, y_rectangular, 'k', linewidth=2, label='Rectangular')\n",
    "\n",
    "# Highlight kernel regression concept\n",
    "plt.axvline(0, color='gray', linestyle=':', alpha=0.6)\n",
    "plt.text(0.05, 0.4, 'Higher weight near $x_0$', fontsize=18, color='black', alpha=0.7)\n",
    "plt.text(1.1, 0.1, 'Lower weight far from $x_0$', fontsize=18, color='black', alpha=0.7)\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('$x - x_0$', fontsize=15)\n",
    "plt.ylabel('Kernel weight', fontsize=15)\n",
    "plt.title('Kernel Functions for Kernel Regression', fontsize=14)\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True, linestyle=':', alpha=0.5)\n",
    "plt.savefig('../figures/loess_kernel.pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Synthetic Dataset Generation with Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Set seed for reproducibility\n",
    "np.random.seed(420)\n",
    "\n",
    "# Step 2: Generate synthetic data\n",
    "n_samples = 1000  # Number of samples\n",
    "n_features = 6    # Number of features\n",
    "\n",
    "# Generate random feature values (X) from a normal distribution\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# Define coefficients (betas) for the linear model\n",
    "betas = np.array([1.5, -2.0, 0.8, 1.2, -0.5, 0.3])\n",
    "\n",
    "# Generate random noise (epsilon)\n",
    "epsilon = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Compute the response variable Y using the linear equation\n",
    "Y = np.dot(X, betas) + epsilon\n",
    "\n",
    "# Step 3: Create a DataFrame\n",
    "columns = [f'X{i+1}' for i in range(n_features)]  # Feature names\n",
    "data = pd.DataFrame(X, columns=columns)\n",
    "data['Y'] = Y  # Add the response variable to the DataFrame\n",
    "\n",
    "# Step 4: Compute the correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Step 5: Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)\n",
    "#plt.title('Correlation Matrix Heatmap')\n",
    "plt.savefig('../figures/heatmap_interaction.pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Residual Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 22\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(500, 1000, 100)\n",
    "\n",
    "# Create a line equation\n",
    "y = 4.0*x + 7.0\n",
    "\n",
    "# Add Gaussian noise\n",
    "mu = 0  # Mean of the Gaussian noise\n",
    "sigma = 20  # Standard deviation of the Gaussian noise\n",
    "noise = np.random.normal(mu, sigma, y.shape)\n",
    "y_noisy = y + noise\n",
    "\n",
    "## Make a plot\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plt.scatter(x, y_noisy)\n",
    "fig.patch.set_alpha(0.0)\n",
    "plt.xlabel('House Size (sq ft)')\n",
    "plt.ylabel('House Price (100K USD)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "plt.rcParams['font.size'] = 25\n",
    "linearModel = LinearRegression()\n",
    "linearModel.fit(x.reshape(-1, 1), y_noisy)\n",
    "yhat = linearModel.predict(x.reshape(-1, 1))\n",
    "error = yhat - y_noisy\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plt.scatter(x, error)\n",
    "fig.patch.set_alpha(0.0)\n",
    "plt.xlabel('Predictor $x$', fontsize=25)\n",
    "plt.ylabel('Residual $e$', fontsize=25)\n",
    "plt.grid(which='both')\n",
    "plt.savefig('../figures/normal_residual_plot.pdf', transparent=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume X and y are your data\n",
    "x = sm.add_constant(x)  # Adds a constant term to the predictor\n",
    "model = sm.OLS(y_noisy, x).fit()\n",
    "\n",
    "# Get the residuals\n",
    "residuals = model.resid\n",
    "\n",
    "# Create Q-Q plot\n",
    "plt.figure(figsize=(4, 8))\n",
    "sm.qqplot(residuals, line='s')  # 's' adds a reference line\n",
    "plt.title('Q-Q Plot of Residuals')\n",
    "plt.savefig('../figures/qq_plot.pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "plt.rcParams['font.size'] = 25\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate data for Homoscedasticity\n",
    "X_homoscedastic = np.random.uniform(0, 10, 100).reshape(-1, 1)\n",
    "y_homoscedastic = 2 * X_homoscedastic.squeeze() + np.random.normal(0, 1, 100)\n",
    "\n",
    "# Fit linear regression model\n",
    "model_homoscedastic = LinearRegression()\n",
    "model_homoscedastic.fit(X_homoscedastic, y_homoscedastic)\n",
    "y_pred_homoscedastic = model_homoscedastic.predict(X_homoscedastic)\n",
    "residuals_homoscedastic = y_homoscedastic - y_pred_homoscedastic\n",
    "\n",
    "# Simulate data for Heteroscedasticity\n",
    "X_heteroscedastic = np.random.uniform(0, 10, 100).reshape(-1, 1)\n",
    "y_heteroscedastic = 2 * X_heteroscedastic.squeeze() + np.random.normal(0, X_heteroscedastic.squeeze())\n",
    "\n",
    "# Fit linear regression model\n",
    "model_heteroscedastic = LinearRegression()\n",
    "model_heteroscedastic.fit(X_heteroscedastic, y_heteroscedastic)\n",
    "y_pred_heteroscedastic = model_heteroscedastic.predict(X_heteroscedastic)\n",
    "residuals_heteroscedastic = y_heteroscedastic - y_pred_heteroscedastic\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Homoscedasticity plot\n",
    "axes[0].scatter(X_homoscedastic, residuals_homoscedastic, color='blue', alpha=0.6)\n",
    "axes[0].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[0].set_title('Homoscedasticity')\n",
    "axes[0].set_xlabel('X')\n",
    "axes[0].set_ylabel('Residuals')\n",
    "\n",
    "# Heteroscedasticity plot\n",
    "axes[1].scatter(X_heteroscedastic, residuals_heteroscedastic, color='green', alpha=0.6)\n",
    "axes[1].axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "axes[1].set_title('Heteroscedasticity')\n",
    "axes[1].set_xlabel('X')\n",
    "axes[1].set_ylabel('Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/Homoscedasticity_vs_Heteroscedasticity.pdf', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Multiple Linear Regression using Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data From Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rahulbhadani/CPE490_590_Sp2025/refs/heads/master/Data/Concrete_Compressive_Strength/Concrete_Data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename columns to more accessible format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping the old column names to the new ones\n",
    "new_column_names = {\n",
    "    'Cement (component 1)(kg in a m^3 mixture)': 'Cement_Amount',\n",
    "    'Blast Furnace Slag (component 2)(kg in a m^3 mixture)': 'Blast_Furnace_Slag_Amount',\n",
    "    'Fly Ash (component 3)(kg in a m^3 mixture)': 'Fly_Ash_Amount',\n",
    "    'Water  (component 4)(kg in a m^3 mixture)': 'Water_Amount',\n",
    "    'Superplasticizer (component 5)(kg in a m^3 mixture)': 'Superplasticizer_Amount',\n",
    "    'Coarse Aggregate  (component 6)(kg in a m^3 mixture)': 'Coarse_Aggregate_Amount',\n",
    "    'Fine Aggregate (component 7)(kg in a m^3 mixture)': 'Fine_Aggregate_Amount',\n",
    "    'Age (day)': 'Age',\n",
    "    'Concrete compressive strength(MPa, megapascals) ': 'Concrete_Strength'\n",
    "}\n",
    "\n",
    "# Rename the columns using the rename method\n",
    "df.rename(columns=new_column_names, inplace=True)\n",
    "\n",
    "# Check the updated column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are only going to use three features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[['Cement_Amount', 'Blast_Furnace_Slag_Amount','Fly_Ash_Amount']]\n",
    "y = df[['Concrete_Strength']]\n",
    "# Separate features and labels\n",
    "x = df_filtered.values.astype(np.float64)\n",
    "y = y.values.reshape(-1, 1).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize features vs response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_filtered is a DataFrame and y is already a NumPy array\n",
    "x = df_filtered.values.astype(np.float64)  # Convert DataFrame to NumPy array\n",
    "y = y.astype(np.float64)  # Ensure y is a NumPy array of type float64\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=x[:, 0],  # Cement_Amount\n",
    "    y=x[:, 1],  # Blast_Furnace_Slag_Amount\n",
    "    z=y[:, 0],  # Concrete_Strength\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=5,\n",
    "        color=y[:, 0],  # Color by Charge Capacity\n",
    "        colorscale='Viridis',  # Choose a colorscale\n",
    "        opacity=0.8\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Set layout\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='Cement (component 1)(kg in a m^3 mixture)',\n",
    "        yaxis_title='Blast Furnace Slag (component 2)(kg in a m^3 mixture)',\n",
    "        zaxis_title='Concrete compressive strength(MPa, megapascals) '\n",
    "    ),\n",
    "    title='3D Plot of Current and Voltage vs Charge Capacity'\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 0], y[:, 0])\n",
    "plt.xlabel('Cement_Amount')\n",
    "plt.ylabel('Concrete Strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 1], y[:, 0])\n",
    "plt.xlabel('Blast_Furnace_Slag_Amount')\n",
    "plt.ylabel('Concrete Strength')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x[:, 2], y[:, 0])\n",
    "plt.xlabel('Fly_Ash_Amount')\n",
    "plt.ylabel('Concrete Strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Simple Linear Regression to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_Train, Y_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.coef_, regressor.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "# error\n",
    "Y_Pred = regressor.predict(X_Train)\n",
    "\n",
    "e= sm.mean_squared_error(Y_Train, Y_Pred)\n",
    "print(\"MSE = {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Squared Error on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "# error\n",
    "Y_Pred = regressor.predict(X_Test)\n",
    "e= sm.mean_squared_error(Y_Test, Y_Pred)\n",
    "print(\"MSE = {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "ridgeModel = Lasso(alpha = 5)\n",
    "ridgeModel.fit(X_Train, Y_Train)\n",
    "ridgeModel.score(X_Test, Y_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "# error\n",
    "Y_Pred = ridgeModel.predict(X_Train)\n",
    "\n",
    "e= sm.mean_squared_error(Y_Train, Y_Pred)\n",
    "print(\"MSE = {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as sm\n",
    "# error\n",
    "Y_Pred = ridgeModel.predict(X_Test)\n",
    "\n",
    "e= sm.mean_squared_error(Y_Test, Y_Pred)\n",
    "print(\"MSE = {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multiple Regression using StatsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Serif'\n",
    "plt.rcParams['font.size'] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/rahulbhadani/CPE490_590_Sp2025/refs/heads/master/Data/Advertising/Advertising.csv', index_col=0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains TV Budget, Radio Budget and Newspaper Budget for an advertisement of a product at a company and Sales.\n",
    "\n",
    "Our goal is to predict sales based on TV Budget, Radio Budget and Newspaper Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with 1 row and 3 columns of subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Adjust figsize for better visualization\n",
    "\n",
    "# Define colors, marker size, and other properties\n",
    "colors = ['blue', 'green', 'red']  # Different colors for each subplot\n",
    "marker_size = 50  # Marker size\n",
    "marker_edge_color = 'black'  # Edge color of markers\n",
    "marker_face_colors = ['lightblue', 'lightgreen', 'pink']  # Face colors for markers\n",
    "\n",
    "# Scatter plot for TV vs Sales\n",
    "axes[0].scatter(df['TV'], df['Sales'], s=marker_size, c=marker_face_colors[0], \n",
    "                edgecolor=marker_edge_color, label='TV vs Sales')\n",
    "axes[0].set_title('TV vs Sales', fontsize=14)\n",
    "axes[0].set_xlabel('TV Advertising Budget', fontsize=12)\n",
    "axes[0].set_ylabel('Sales', fontsize=12)\n",
    "axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Scatter plot for Radio vs Sales\n",
    "axes[1].scatter(df['Radio'], df['Sales'], s=marker_size, c=marker_face_colors[1], \n",
    "                edgecolor=marker_edge_color, label='Radio vs Sales')\n",
    "axes[1].set_title('Radio vs Sales', fontsize=14)\n",
    "axes[1].set_xlabel('Radio Advertising Budget', fontsize=12)\n",
    "axes[1].set_ylabel('Sales', fontsize=12)\n",
    "axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Scatter plot for Newspaper vs Sales\n",
    "axes[2].scatter(df['Newspaper'], df['Sales'], s=marker_size, c=marker_face_colors[2], \n",
    "                edgecolor=marker_edge_color, label='Newspaper vs Sales')\n",
    "axes[2].set_title('Newspaper vs Sales', fontsize=14)\n",
    "axes[2].set_xlabel('Newspaper Advertising Budget', fontsize=12)\n",
    "axes[2].set_ylabel('Sales', fontsize=12)\n",
    "axes[2].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add some spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[['TV', 'Radio', 'Newspaper']]\n",
    "y = df[['Sales']]\n",
    "# Separate features and labels\n",
    "x = df_filtered.values.astype(np.float64)\n",
    "y = y.values.reshape(-1, 1).astype(np.float64)\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(x, y, test_size = 1/3, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Simple Linear Regression to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = sm.add_constant(X_Train) \n",
    "est = sm.OLS(Y_Train, xt).fit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the Summary of the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In the above result, we see that $R^2$ coefficient of determination was $0.907$,and estimated coefficients were $w_0 = 2.9038$, $w_1 = 0.0443\t$, $w_2 = 0.1966$, and $w_3 = 0.0026$.\n",
    "We can also see their respective 95% confidence interval as [2.175,\t3.632], [0.041,\t0.048], [0.178,\t0.216], and [-0.011,\t0.017].\n",
    "\n",
    "Note: the answer might be different if rerun the notebook and training and test split will happen randomly everytime the whole notebook is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any feature has a high p-value (>0.05), it might not be contributing significantly to the prediction of Sales. Looking at P > |t|, we see that P-value is 0.712 for x3 which means Newspaper is not contributing significantly to sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error on Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred = est.predict(xt)\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(Y_Train.reshape(-1,), y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals on training data\n",
    "residuals = Y_Train.reshape(-1,) - y_pred\n",
    "\n",
    "# Plot residuals vs fitted values\n",
    "plt.scatter(y_pred, residuals, color='blue', edgecolor='black')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Fitted Values', fontsize=14)\n",
    "plt.xlabel('Fitted Values', fontsize=12)\n",
    "plt.ylabel('Residuals', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No funnel shaped residual, hence it doesn't violate the assumption of constant variance in linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQ Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Q-Q plot for residuals\n",
    "stats.probplot(residuals.ravel(), dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot of Residuals', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem strong deviation from normality of residuals assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = sm.add_constant(X_Test)\n",
    "\n",
    "# Make a prediction\n",
    "y_pred = est.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Squared Error on test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(Y_Test, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Feature importance refers to techniques that calculate a score for all input features in a machine learning model. These scores represent how useful or valuable each feature is in predicting the target variable. Higher value means more important feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Lasso\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': ['Constant', 'TV', 'Radio', 'Newspaper'],\n",
    "    'Coefficient': est.params\n",
    "})\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation MSE\n",
    "In k-fold cross-validation , the dataset is divided into k subsets (folds). The model is trained on kâˆ’1 folds and tested on the remaining fold.\n",
    "This process is repeated k times, with each fold serving as the test set once. The MSE is then averaged across all k iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Using scikit-learn for cross-validation\n",
    "lr = LinearRegression()\n",
    "scores = cross_val_score(lr, x, y, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_scores = -scores\n",
    "print(f\"Cross-validated MSE: {mse_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Ridge (L2) regularization\n",
    "ridge_model = sm.OLS(Y_Train, xt)\n",
    "ridge_results = ridge_model.fit_regularized(method='elastic_net', alpha=10.0, L1_wt=0.0)  # L1_wt=0 for Ridge\n",
    "\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred_ridge = ridge_results.predict(xt)\n",
    "y_test_pred_ridge = ridge_results.predict(sm.add_constant(X_Test))\n",
    "\n",
    "# Calculate MSE for Ridge\n",
    "mse_train_ridge = mean_squared_error(Y_Train, y_train_pred_ridge)\n",
    "mse_test_ridge = mean_squared_error(Y_Test, y_test_pred_ridge)\n",
    "print(f\"Ridge Training MSE: {mse_train_ridge}\")\n",
    "print(f\"Ridge Testing MSE: {mse_test_ridge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Lasso (L1) regularization\n",
    "lasso_model = sm.OLS(Y_Train, xt)\n",
    "lasso_results = lasso_model.fit_regularized(method='elastic_net', alpha=0.0, L1_wt=40.0)  # L1_wt=1 for Lasso\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred_lasso = lasso_results.predict(xt)\n",
    "y_test_pred_lasso = lasso_results.predict(sm.add_constant(X_Test))\n",
    "\n",
    "# Calculate MSE for Lasso\n",
    "mse_train_lasso = mean_squared_error(Y_Train, y_train_pred_lasso)\n",
    "mse_test_lasso = mean_squared_error(Y_Test, y_test_pred_lasso)\n",
    "print(f\"Lasso Training MSE: {mse_train_lasso}\")\n",
    "print(f\"Lasso Testing MSE: {mse_test_lasso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Implementation of Multiple Linear Regression Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "import torch\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/rahulbhadani/CPE490_590_Sp2025/refs/heads/master/Data/Advertising/Advertising.csv', index_col=0)\n",
    "\n",
    "# Features and target\n",
    "X = df[['TV', 'Radio', 'Newspaper']].values.astype(np.float32)\n",
    "y = df['Sales'].values.astype(np.float32)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train)\n",
    "y_train_tensor = torch.tensor(y_train).view(-1, 1)  # Reshape to column vector\n",
    "X_test_tensor = torch.tensor(X_test)\n",
    "y_test_tensor = torch.tensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "W = torch.randn(input_dim, 1, requires_grad=True, dtype=torch.float32)  # Random initialization for weights\n",
    "b = torch.randn(1, requires_grad=True, dtype=torch.float32)            # Random initialization for bias\n",
    "\n",
    "# Define the linear regression model\n",
    "def model(X):\n",
    "    return X @ W + b  # Matrix multiplication: X @ W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Mean Squared Error loss\n",
    "def mse_loss(Y_pred, Y_true):\n",
    "    return torch.mean((Y_pred - Y_true) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.00001\n",
    "num_epochs = 1000000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predictions\n",
    "    Y_pred = model(X_train_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = mse_loss(Y_pred, y_train_tensor)\n",
    "\n",
    "    # Backward pass: Compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights and bias manually\n",
    "    with torch.no_grad():  # Disable gradient tracking during updates\n",
    "        W -= learning_rate * W.grad\n",
    "        b -= learning_rate * b.grad\n",
    "\n",
    "    # Zero gradients for the next iteration\n",
    "    W.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test data\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    Y_test_pred = model(X_test_tensor)\n",
    "    test_loss = mse_loss(Y_test_pred, y_test_tensor)\n",
    "    print(f'Test MSE: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        # Initialize weights and bias\n",
    "        self.weights = nn.Parameter(torch.randn(input_dim, 1))  # Random initialization\n",
    "        self.bias = nn.Parameter(torch.randn(1))               # Random initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform matrix multiplication: y_pred = X @ W + b\n",
    "        return x @ self.weights + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "model = LinearRegressionModel(input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10000/100000], Loss: 2.9943\n",
      "Epoch [20000/100000], Loss: 2.9688\n",
      "Epoch [30000/100000], Loss: 2.9448\n",
      "Epoch [40000/100000], Loss: 2.9223\n",
      "Epoch [50000/100000], Loss: 2.9009\n",
      "Epoch [60000/100000], Loss: 2.8808\n",
      "Epoch [70000/100000], Loss: 2.8618\n",
      "Epoch [80000/100000], Loss: 2.8439\n",
      "Epoch [90000/100000], Loss: 2.8270\n",
      "Epoch [100000/100000], Loss: 2.8110\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 100000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: Compute predictions\n",
    "    y_pred = model(X_train_tensor)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(y_pred, y_train_tensor)\n",
    "\n",
    "    # Backward pass: Compute gradients\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()        # Compute gradients\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print progress every 100 epochs\n",
    "    if (epoch + 1) % 10000 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 3.6898\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    y_test_pred = model(X_test_tensor)\n",
    "    test_loss = criterion(y_test_pred, y_test_tensor)\n",
    "    print(f'Test MSE: {test_loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPE490590",
   "language": "python",
   "name": "cpe490590"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
